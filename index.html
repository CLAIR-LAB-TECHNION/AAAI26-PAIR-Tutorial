<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>AAAI-26 Tutorial: Plan, Activity and Intent Recognition (PAIR)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="description" content="AAAI-26 tutorial on Plan, Activity and Intent Recognition (PAIR)" />
  <style>
    :root {
      --accent: #0b7285;
      --accent-light: #e3fafc;
      --bg: #f8f9fa;
      --text: #212529;
      --muted: #6c757d;
    }
    * {
      box-sizing: border-box;
    }
    body {
      margin: 0;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI",
        sans-serif;
      background: var(--bg);
      color: var(--text);
      line-height: 1.6;
    }
    header {
      background: white;
      border-bottom: 1px solid #dee2e6;
      padding: 1.5rem 1.5rem 1rem;
      position: sticky;
      top: 0;
      z-index: 10;
    }
    header h1 {
      margin: 0;
      font-size: 1.6rem;
      color: var(--accent);
    }
    header p {
      margin: 0.2rem 0 0;
      color: var(--muted);
      font-size: 0.95rem;
    }
    main {
      max-width: 960px;
      margin: 1.5rem auto 3rem;
      padding: 0 1rem;
    }
    .badge-row {
      display: flex;
      flex-wrap: wrap;
      gap: 0.4rem;
      margin: 0.8rem 0 0;
    }
    .badge {
      font-size: 0.8rem;
      padding: 0.15rem 0.55rem;
      border-radius: 999px;
      border: 1px solid #ced4da;
      background: white;
      color: var(--muted);
      white-space: nowrap;
    }
    .hero {
      background: white;
      border-radius: 0.75rem;
      padding: 1.5rem 1.5rem 1.25rem;
      box-shadow: 0 6px 18px rgba(0, 0, 0, 0.03);
      border: 1px solid #e9ecef;
      margin-bottom: 1.8rem;
    }
    .hero h2 {
      margin-top: 0;
      font-size: 1.3rem;
    }
    .hero p {
      margin-top: 0.5rem;
    }
    .meta-grid {
      display: grid;
      gap: 0.75rem 2rem;
      margin-top: 1rem;
      font-size: 0.95rem;
    }
    .meta-label {
      font-weight: 600;
      color: var(--muted);
      font-size: 0.85rem;
      text-transform: uppercase;
      letter-spacing: 0.04em;
    }
    .section {
      margin-bottom: 2rem;
    }
    .section h2 {
      font-size: 1.2rem;
      border-bottom: 2px solid var(--accent-light);
      padding-bottom: 0.35rem;
      margin-bottom: 0.75rem;
    }
    .two-column {
      display: grid;
      gap: 1.5rem;
    }
    @media (min-width: 800px) {
      .meta-grid {
        grid-template-columns: repeat(3, minmax(0, 1fr));
      }
      .two-column {
        grid-template-columns: 2fr 1.5fr;
      }
    }
    ul, ol {
      padding-left: 1.15rem;
      margin-top: 0.2rem;
    }
    .card {
      background: white;
      border-radius: 0.75rem;
      padding: 1.1rem 1.25rem;
      border: 1px solid #e9ecef;
    }
    .presenter {
      margin-bottom: 1rem;
    }
    .presenter:last-child {
      margin-bottom: 0;
    }
    .presenter-name {
      font-weight: 600;
      color: var(--accent);
    }
    .presenter-affil {
      font-size: 0.9rem;
      color: var(--muted);
    }
    .presenter-email a {
      color: var(--accent);
      text-decoration: none;
      font-size: 0.9rem;
    }
    .presenter-email a:hover {
      text-decoration: underline;
    }
    .tagline {
      font-style: italic;
      color: var(--muted);
      margin-top: 0.4rem;
    }
    .pill {
      display: inline-block;
      background: var(--accent-light);
      color: var(--accent);
      padding: 0.25rem 0.6rem;
      font-size: 0.8rem;
      border-radius: 999px;
      font-weight: 500;
      margin: 0.1rem;
    }
    footer {
      text-align: center;
      font-size: 0.8rem;
      color: var(--muted);
      padding: 1.5rem 1rem 2rem;
    }
    a {
      color: var(--accent);
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
  </style>
</head>
<body>
  <header>
    <h1>Plan, Activity and Intent Recognition (PAIR)</h1>
    <p>AAAI-26 Tutorial • Tuesday, January 20 • 8:30am–12:30pm</p>
    <p>Location: Singapore EXPO Convention &amp; Exhibition Centre</p>
    <div class="badge-row">
      <span class="badge">AAAI-26</span>
      <span class="badge">Half-day Tutorial</span>
      <span class="badge">8:30am – 12:30pm</span>
      <span class="badge">January 20, 2026</span>
      <span class="badge">Singapore EXPO</span>
    </div>
  </header>

  <main>
    <section class="hero">
      <h2>About the Tutorial</h2>
      <p>
        Despite rapid progress in machine learning, <strong>real-time, online inference
        of agents’ intentions</strong> remains one of the enduring grand challenges in AI.
        Plan, activity, intent, and goal recognition focus on inferring what
        software agents, robots, or humans are trying to achieve from observations
        of their behavior and interactions.
      </p>
      <p>
        This tutorial targets AI students and researchers who want to understand
        and apply recognition techniques in their own work, and who are looking
        for new research directions grounded in this rich, cross-cutting area
        of AI.
      </p>

      <div class="meta-grid">
        <div>
          <div class="meta-label">Goal</div>
          <div>
            Provide a unified, up-to-date introduction to plan, activity, intent,
            and goal recognition: core concepts, problem formulations, algorithms,
            and applications.
          </div>
        </div>
        <div>
          <div class="meta-label">Who should attend?</div>
          <div>
            Graduate students, researchers, and practitioners with interest in
            planning, reinforcement learning, human–robot interaction, multi-agent
            systems, or intent inference.
          </div>
        </div>
        <div>
          <div class="meta-label">Prerequisites</div>
          <div>
            Familiarity with basic AI concepts, probabilistic reasoning, and
            planning is recommended. Prior exposure to Bayesian inference or
            logic-based reasoning is helpful but not required.
          </div>
        </div>
      </div>
    </section>

    <section class="section two-column">
      <div>
        <h2>Motivation &amp; Scope</h2>
        <div class="card">
          <p>
            Recognition problems arise in a wide range of domains: assistive
            technologies, software assistants, computer and network security,
            behavior recognition, human–robot collaboration, and more. Techniques
            span user modeling, machine vision, automated planning, intelligent
            user interfaces, HCI, multi-agent systems, natural language
            understanding, and machine learning.
          </p>
          <p>
            While this diversity has produced a wealth of ideas and tools, it has
            also led to fragmentation. This tutorial <strong>brings together
            perspectives and methods from multiple AI subfields</strong> to offer
            a coherent view of the plan, activity, intent, and goal recognition
            landscape.
          </p>
          <p class="tagline">
            Building on the successful AAAI-19 PAIR tutorial and our 2021 book,
            we present an updated and expanded view of the field.
          </p>
        </div>
      </div>
      <div>
        <h2>Keywords</h2>
        <div class="card">
          <p>
            <span class="pill">Plan recognition</span>
            <span class="pill">Goal recognition</span>
            <span class="pill">Activity recognition</span>
            <span class="pill">Behavior recognition</span>
            <span class="pill">Temporal pattern recognition</span>
            <span class="pill">Probabilistic inference</span>
            <span class="pill">Reasoning under uncertainty</span>
            <span class="pill">Theory of mind</span>
            <span class="pill">Human–AI collaboration</span>
            <span class="pill">Multi-agent systems</span>
          </p>
        </div>
      </div>
    </section>

    <section class="section">
      <h2>Detailed Outline</h2>
      <div class="card">
        <ol>
          <li>
            <strong>Introduction to recognition problems</strong><br />
            Plan, activity, intent, and goal recognition: basic concepts and
            problem space.
          </li>
          <li>
            <strong>Motivating scenarios across domains</strong><br />
            Examples from human–robot collaboration, security, assistive
            technologies, and other application areas.
          </li>
          <li>
            <strong>Formal problem definitions</strong><br />
            Distinctions among plan, activity, intent, and goal recognition
            tasks; relationships between them.
          </li>
          <li>
            <strong>Computational representations</strong><br />
            Logic-based, probabilistic, machine learning, and hybrid models
            used for recognition.
          </li>
          <li>
            <strong>Algorithms and inference methods</strong><br />
            Core approaches for performing online and offline recognition in
            different settings.
          </li>
          <li>
            <strong>Evaluation methodologies and benchmarks</strong><br />
            How to evaluate recognition systems: datasets, metrics, and
            experimental design.
          </li>
          <li>
            <strong>Current challenges &amp; open directions</strong><br />
            Scalability, real-time reasoning, robustness, integration with
            learning, human–AI collaboration, and other open research questions.
          </li>
        </ol>
      </div>
    </section>

    <section class="section">
      <h2>Presenters</h2>
      <div class="card">
        <div class="presenter">
          <div class="presenter-name">Sarah Keren</div>
          <div class="presenter-affil">
            Senior Lecturer, Faculty of Computer Science, Technion – Israel Institute of Technology
          </div>
          <div class="presenter-email">
            Contact: <a href="mailto:sarahk@technion.ac.il">sarahk@technion.ac.il</a>
          </div>
          <p>
            Sarah’s research focuses on multi-agent environment design: creating
            environments that enhance agent capabilities and enable effective
            multi-robot and human–robot collaboration. She combines model-based
            reasoning, decision-making under uncertainty, game theory, and
            multi-agent learning. Her doctoral work introduced
            <em>Goal Recognition Design</em>, a framework for improving goal
            inference via environment redesign.
          </p>
        </div>

        <div class="presenter">
          <div class="presenter-name">Reuth Mirsky</div>
          <div class="presenter-affil">
            Assistant Professor, Computer Science Department, Tufts University
          </div>
          <div class="presenter-email">
            Contact:
            <a href="mailto:reuth.mirsky@tufts.edu">reuth.mirsky@tufts.edu</a>
          </div>
          <p>
            Reuth leads the GOLD (goal optimization using learning and
            decision-making) lab. Her work develops algorithms and frameworks
            that challenge traditional assumptions about intelligent agents. She
            is an active contributor to the AI and HRI communities and has
            co-organized more than 15 events on related topics at major AI
            conferences, including the PAIR and RaD-AI workshop series.
          </p>
        </div>

        <div class="presenter">
          <div class="presenter-name">Christopher Geib</div>
          <div class="presenter-affil">
            Principal Scientist, Charles River Analytics
          </div>
          <div class="presenter-email">
            Contact: <a href="mailto:cwgeib@gmail.com">cwgeib@gmail.com</a>
          </div>
          <p>
            Chris is the principal architect of multiple probabilistic plan
            recognition systems, including the ELEXIR system, which demonstrates
            state-of-the-art plan recognition and planning capabilities using a
            single, shared, and learnable domain representation.
          </p>
        </div>
      </div>
    </section>

    <section class="section two-column">
      <div>
        <h2>History &amp; Expected Audience</h2>
        <div class="card">
          <p>
            This tutorial was previously presented at AAAI-19, where it attracted
            approximately 60 participants. For AAAI-26, we anticipate
            <strong>50–70 participants</strong>, including researchers and
            students from planning, machine learning, human–robot interaction,
            and multi-agent systems.
          </p>
          <p>
            The AAAI-26 edition is updated and expanded with material from our
            co-authored book and recent advances in plan and goal recognition.
          </p>
        </div>
      </div>
      <div>
        <h2>Supplementary Materials</h2>
        <div class="card">
          <ul>
            <li>Slides from previous PAIR tutorials</li>
            <li>Survey papers on plan, activity, intent, and goal recognition</li>
            <li>Links to relevant toolkits and software</li>
            <li>
              Chapters from <em>Introduction to Symbolic Plan and Goal
              Recognition</em> (Mirsky, Keren, &amp; Geib, 2021)
            </li>
          </ul>
        </div>
      </div>
    </section>

    <section class="section">
      <h2>References</h2>
      <div class="card">
        <ul>
          <li>
            S. Keren, R. Mirsky, and C. Geib. “Plan Activity and Intent
            Recognition Tutorial.” AAAI, 2019.
          </li>
          <li>
            R. Mirsky, S. Keren, and C. Geib.
            <em>Introduction to Symbolic Plan and Goal Recognition</em>.
            Springer, 2021.
          </li>
        </ul>
      </div>
    </section>
  </main>

  <footer>
    &copy; 2026 PAIR Tutorial Organizers · AAAI-26 · Singapore EXPO
  </footer>
</body>
</html>
